"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.curlSnippets = exports.snippetFile = exports.snippetZeroShotClassification = exports.snippetTextGeneration = exports.snippetBasic = void 0;
exports.getCurlInferenceSnippet = getCurlInferenceSnippet;
const inference_providers_js_1 = require("../inference-providers.js");
const common_js_1 = require("./common.js");
const inputs_js_1 = require("./inputs.js");
const snippetBasic = (model, accessToken, provider) => {
    if (provider !== "hf-inference") {
        return [];
    }
    return [
        {
            client: "curl",
            content: `\
curl https://api-inference.huggingface.co/models/${model.id} \\
	-X POST \\
	-d '{"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model, true)}}' \\
	-H 'Content-Type: application/json' \\
	-H 'Authorization: Bearer ${accessToken || `{API_TOKEN}`}'`,
        },
    ];
};
exports.snippetBasic = snippetBasic;
const snippetTextGeneration = (model, accessToken, provider, opts) => {
    if (model.tags.includes("conversational")) {
        const baseUrl = provider === "hf-inference"
            ? `https://api-inference.huggingface.co/models/${model.id}/v1/chat/completions`
            : inference_providers_js_1.HF_HUB_INFERENCE_PROXY_TEMPLATE.replace("{{PROVIDER}}", provider) + "/v1/chat/completions";
        // Conversational model detected, so we display a code snippet that features the Messages API
        const streaming = opts?.streaming ?? true;
        const exampleMessages = (0, inputs_js_1.getModelInputSnippet)(model);
        const messages = opts?.messages ?? exampleMessages;
        const config = {
            ...(opts?.temperature ? { temperature: opts.temperature } : undefined),
            max_tokens: opts?.max_tokens ?? 500,
            ...(opts?.top_p ? { top_p: opts.top_p } : undefined),
        };
        return [
            {
                client: "curl",
                content: `curl '${baseUrl}' \\
-H 'Authorization: Bearer ${accessToken || `{API_TOKEN}`}' \\
-H 'Content-Type: application/json' \\
--data '{
    "model": "${model.id}",
    "messages": ${(0, common_js_1.stringifyMessages)(messages, {
                    indent: "\t",
                    attributeKeyQuotes: true,
                    customContentEscaper: (str) => str.replace(/'/g, "'\\''"),
                })},
    ${(0, common_js_1.stringifyGenerationConfig)(config, {
                    indent: "\n    ",
                    attributeKeyQuotes: true,
                    attributeValueConnector: ": ",
                })},
    "stream": ${!!streaming}
}'`,
            },
        ];
    }
    else {
        return (0, exports.snippetBasic)(model, accessToken, provider);
    }
};
exports.snippetTextGeneration = snippetTextGeneration;
const snippetZeroShotClassification = (model, accessToken, provider) => {
    if (provider !== "hf-inference") {
        return [];
    }
    return [
        {
            client: "curl",
            content: `curl https://api-inference.huggingface.co/models/${model.id} \\
	-X POST \\
	-d '{"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model, true)}, "parameters": {"candidate_labels": ["refund", "legal", "faq"]}}' \\
	-H 'Content-Type: application/json' \\
	-H 'Authorization: Bearer ${accessToken || `{API_TOKEN}`}'`,
        },
    ];
};
exports.snippetZeroShotClassification = snippetZeroShotClassification;
const snippetFile = (model, accessToken, provider) => {
    if (provider !== "hf-inference") {
        return [];
    }
    return [
        {
            client: "curl",
            content: `curl https://api-inference.huggingface.co/models/${model.id} \\
	-X POST \\
	--data-binary '@${(0, inputs_js_1.getModelInputSnippet)(model, true, true)}' \\
	-H 'Authorization: Bearer ${accessToken || `{API_TOKEN}`}'`,
        },
    ];
};
exports.snippetFile = snippetFile;
exports.curlSnippets = {
    // Same order as in tasks/src/pipelines.ts
    "text-classification": exports.snippetBasic,
    "token-classification": exports.snippetBasic,
    "table-question-answering": exports.snippetBasic,
    "question-answering": exports.snippetBasic,
    "zero-shot-classification": exports.snippetZeroShotClassification,
    translation: exports.snippetBasic,
    summarization: exports.snippetBasic,
    "feature-extraction": exports.snippetBasic,
    "text-generation": exports.snippetTextGeneration,
    "image-text-to-text": exports.snippetTextGeneration,
    "text2text-generation": exports.snippetBasic,
    "fill-mask": exports.snippetBasic,
    "sentence-similarity": exports.snippetBasic,
    "automatic-speech-recognition": exports.snippetFile,
    "text-to-image": exports.snippetBasic,
    "text-to-speech": exports.snippetBasic,
    "text-to-audio": exports.snippetBasic,
    "audio-to-audio": exports.snippetFile,
    "audio-classification": exports.snippetFile,
    "image-classification": exports.snippetFile,
    "image-to-text": exports.snippetFile,
    "object-detection": exports.snippetFile,
    "image-segmentation": exports.snippetFile,
};
function getCurlInferenceSnippet(model, accessToken, provider, opts) {
    return model.pipeline_tag && model.pipeline_tag in exports.curlSnippets
        ? exports.curlSnippets[model.pipeline_tag]?.(model, accessToken, provider, opts) ?? []
        : [];
}
