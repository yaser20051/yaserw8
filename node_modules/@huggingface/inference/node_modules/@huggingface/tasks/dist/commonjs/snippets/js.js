"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.jsSnippets = exports.snippetFile = exports.snippetAutomaticSpeechRecognition = exports.snippetTextToAudio = exports.snippetTextToImage = exports.snippetZeroShotClassification = exports.snippetTextGeneration = exports.snippetBasic = void 0;
exports.getJsInferenceSnippet = getJsInferenceSnippet;
const inference_providers_js_1 = require("../inference-providers.js");
const common_js_1 = require("./common.js");
const inputs_js_1 = require("./inputs.js");
const HFJS_METHODS = {
    "text-classification": "textClassification",
    "token-classification": "tokenClassification",
    "table-question-answering": "tableQuestionAnswering",
    "question-answering": "questionAnswering",
    translation: "translation",
    summarization: "summarization",
    "feature-extraction": "featureExtraction",
    "text-generation": "textGeneration",
    "text2text-generation": "textGeneration",
    "fill-mask": "fillMask",
    "sentence-similarity": "sentenceSimilarity",
};
const snippetBasic = (model, accessToken, provider) => {
    return [
        ...(model.pipeline_tag && model.pipeline_tag in HFJS_METHODS
            ? [
                {
                    client: "huggingface.js",
                    content: `\
import { HfInference } from "@huggingface/inference";

const client = new HfInference("${accessToken || `{API_TOKEN}`}");

const output = await client.${HFJS_METHODS[model.pipeline_tag]}({
	model: "${model.id}",
	inputs: ${(0, inputs_js_1.getModelInputSnippet)(model)},
	provider: "${provider}",
});

console.log(output)
`,
                },
            ]
            : []),
        {
            client: "fetch",
            content: `\
async function query(data) {
	const response = await fetch(
		"https://api-inference.huggingface.co/models/${model.id}",
		{
			headers: {
				Authorization: "Bearer ${accessToken || `{API_TOKEN}`}",
				"Content-Type": "application/json",
			},
			method: "POST",
			body: JSON.stringify(data),
		}
	);
	const result = await response.json();
	return result;
}

query({"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model)}}).then((response) => {
	console.log(JSON.stringify(response));
});`,
        },
    ];
};
exports.snippetBasic = snippetBasic;
const snippetTextGeneration = (model, accessToken, provider, opts) => {
    if (model.tags.includes("conversational")) {
        // Conversational model detected, so we display a code snippet that features the Messages API
        const streaming = opts?.streaming ?? true;
        const exampleMessages = (0, inputs_js_1.getModelInputSnippet)(model);
        const messages = opts?.messages ?? exampleMessages;
        const messagesStr = (0, common_js_1.stringifyMessages)(messages, { indent: "\t" });
        const config = {
            ...(opts?.temperature ? { temperature: opts.temperature } : undefined),
            max_tokens: opts?.max_tokens ?? 500,
            ...(opts?.top_p ? { top_p: opts.top_p } : undefined),
        };
        const configStr = (0, common_js_1.stringifyGenerationConfig)(config, {
            indent: "\n\t",
            attributeValueConnector: ": ",
        });
        if (streaming) {
            return [
                {
                    client: "huggingface.js",
                    content: `import { HfInference } from "@huggingface/inference";

const client = new HfInference("${accessToken || `{API_TOKEN}`}");

let out = "";

const stream = client.chatCompletionStream({
	model: "${model.id}",
	messages: ${messagesStr},
	provider: "${provider}",
	${configStr}
});

for await (const chunk of stream) {
	if (chunk.choices && chunk.choices.length > 0) {
		const newContent = chunk.choices[0].delta.content;
		out += newContent;
		console.log(newContent);
	}  
}`,
                },
                {
                    client: "openai",
                    content: `import { OpenAI } from "openai";

const client = new OpenAI({
	baseURL: "${(0, inference_providers_js_1.openAIbaseUrl)(provider)}",
	apiKey: "${accessToken || `{API_TOKEN}`}"
});

let out = "";

const stream = await client.chat.completions.create({
	model: "${model.id}",
	messages: ${messagesStr},
	${configStr},
	stream: true,
});

for await (const chunk of stream) {
	if (chunk.choices && chunk.choices.length > 0) {
		const newContent = chunk.choices[0].delta.content;
		out += newContent;
		console.log(newContent);
	}  
}`,
                },
            ];
        }
        else {
            return [
                {
                    client: "huggingface.js",
                    content: `import { HfInference } from "@huggingface/inference";

const client = new HfInference("${accessToken || `{API_TOKEN}`}");

const chatCompletion = await client.chatCompletion({
	model: "${model.id}",
	messages: ${messagesStr},
	provider: "${provider}",
	${configStr}
});

console.log(chatCompletion.choices[0].message);`,
                },
                {
                    client: "openai",
                    content: `import { OpenAI } from "openai";

const client = new OpenAI({
	baseURL: "${(0, inference_providers_js_1.openAIbaseUrl)(provider)}",
	apiKey: "${accessToken || `{API_TOKEN}`}"
});

const chatCompletion = await client.chat.completions.create({
	model: "${model.id}",
	messages: ${messagesStr},
	${configStr}
});

console.log(chatCompletion.choices[0].message);`,
                },
            ];
        }
    }
    else {
        return (0, exports.snippetBasic)(model, accessToken, provider);
    }
};
exports.snippetTextGeneration = snippetTextGeneration;
const snippetZeroShotClassification = (model, accessToken) => {
    return [
        {
            client: "fetch",
            content: `async function query(data) {
			const response = await fetch(
				"https://api-inference.huggingface.co/models/${model.id}",
				{
					headers: {
						Authorization: "Bearer ${accessToken || `{API_TOKEN}`}",
						"Content-Type": "application/json",
					},
					method: "POST",
					body: JSON.stringify(data),
				}
			);
			const result = await response.json();
			return result;
		}
		
		query({"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model)}, "parameters": {"candidate_labels": ["refund", "legal", "faq"]}}).then((response) => {
			console.log(JSON.stringify(response));
		});`,
        },
    ];
};
exports.snippetZeroShotClassification = snippetZeroShotClassification;
const snippetTextToImage = (model, accessToken, provider) => {
    return [
        {
            client: "huggingface.js",
            content: `\
import { HfInference } from "@huggingface/inference";

const client = new HfInference("${accessToken || `{API_TOKEN}`}");

const image = await client.textToImage({
	model: "${model.id}",
	inputs: ${(0, inputs_js_1.getModelInputSnippet)(model)},
	parameters: { num_inference_steps: 5 },
	provider: "${provider}",
});
/// Use the generated image (it's a Blob)
`,
        },
        ...(provider === "hf-inference"
            ? [
                {
                    client: "fetch",
                    content: `async function query(data) {
	const response = await fetch(
		"https://api-inference.huggingface.co/models/${model.id}",
		{
			headers: {
				Authorization: "Bearer ${accessToken || `{API_TOKEN}`}",
				"Content-Type": "application/json",
			},
			method: "POST",
			body: JSON.stringify(data),
		}
	);
	const result = await response.blob();
	return result;
}
query({"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model)}}).then((response) => {
	// Use image
});`,
                },
            ]
            : []),
    ];
};
exports.snippetTextToImage = snippetTextToImage;
const snippetTextToAudio = (model, accessToken, provider) => {
    if (provider !== "hf-inference") {
        return [];
    }
    const commonSnippet = `async function query(data) {
		const response = await fetch(
			"https://api-inference.huggingface.co/models/${model.id}",
			{
				headers: {
					Authorization: "Bearer ${accessToken || `{API_TOKEN}`}",
					"Content-Type": "application/json",
				},
				method: "POST",
				body: JSON.stringify(data),
			}
		);`;
    if (model.library_name === "transformers") {
        return [
            {
                client: "fetch",
                content: commonSnippet +
                    `
			const result = await response.blob();
			return result;
		}
		query({"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model)}}).then((response) => {
			// Returns a byte object of the Audio wavform. Use it directly!
		});`,
            },
        ];
    }
    else {
        return [
            {
                client: "fetch",
                content: commonSnippet +
                    `
			const result = await response.json();
			return result;
		}
		
		query({"inputs": ${(0, inputs_js_1.getModelInputSnippet)(model)}}).then((response) => {
			console.log(JSON.stringify(response));
		});`,
            },
        ];
    }
};
exports.snippetTextToAudio = snippetTextToAudio;
const snippetAutomaticSpeechRecognition = (model, accessToken, provider) => {
    return [
        {
            client: "huggingface.js",
            content: `\
import { HfInference } from "@huggingface/inference";

const client = new HfInference("${accessToken || `{API_TOKEN}`}");

const data = fs.readFileSync(${(0, inputs_js_1.getModelInputSnippet)(model)});

const output = await client.automaticSpeechRecognition({
	data,
	model: "${model.id}",
	provider: "${provider}",
});

console.log(output);
`,
        },
        ...(provider === "hf-inference" ? (0, exports.snippetFile)(model, accessToken, provider) : []),
    ];
};
exports.snippetAutomaticSpeechRecognition = snippetAutomaticSpeechRecognition;
const snippetFile = (model, accessToken, provider) => {
    if (provider !== "hf-inference") {
        return [];
    }
    return [
        {
            client: "fetch",
            content: `async function query(filename) {
	const data = fs.readFileSync(filename);
	const response = await fetch(
		"https://api-inference.huggingface.co/models/${model.id}",
		{
			headers: {
				Authorization: "Bearer ${accessToken || `{API_TOKEN}`}",
				"Content-Type": "application/json",
			},
			method: "POST",
			body: data,
		}
	);
	const result = await response.json();
	return result;
}

query(${(0, inputs_js_1.getModelInputSnippet)(model)}).then((response) => {
	console.log(JSON.stringify(response));
});`,
        },
    ];
};
exports.snippetFile = snippetFile;
exports.jsSnippets = {
    // Same order as in tasks/src/pipelines.ts
    "text-classification": exports.snippetBasic,
    "token-classification": exports.snippetBasic,
    "table-question-answering": exports.snippetBasic,
    "question-answering": exports.snippetBasic,
    "zero-shot-classification": exports.snippetZeroShotClassification,
    translation: exports.snippetBasic,
    summarization: exports.snippetBasic,
    "feature-extraction": exports.snippetBasic,
    "text-generation": exports.snippetTextGeneration,
    "image-text-to-text": exports.snippetTextGeneration,
    "text2text-generation": exports.snippetBasic,
    "fill-mask": exports.snippetBasic,
    "sentence-similarity": exports.snippetBasic,
    "automatic-speech-recognition": exports.snippetAutomaticSpeechRecognition,
    "text-to-image": exports.snippetTextToImage,
    "text-to-speech": exports.snippetTextToAudio,
    "text-to-audio": exports.snippetTextToAudio,
    "audio-to-audio": exports.snippetFile,
    "audio-classification": exports.snippetFile,
    "image-classification": exports.snippetFile,
    "image-to-text": exports.snippetFile,
    "object-detection": exports.snippetFile,
    "image-segmentation": exports.snippetFile,
};
function getJsInferenceSnippet(model, accessToken, provider, opts) {
    return model.pipeline_tag && model.pipeline_tag in exports.jsSnippets
        ? exports.jsSnippets[model.pipeline_tag]?.(model, accessToken, provider, opts) ?? []
        : [];
}
